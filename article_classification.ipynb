{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_path = './data/sportoclanky.csv'\n",
    "assert os.path.exists(dataset_file_path)\n",
    "df = pd.read_csv(dataset_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally I would print out `df.head()`, but since the data is too sensitive to be public, only metadata can be used for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background I have empirically checked that all the categories are truly unique, e.g. that there are no duplications due to case sensitivity, spelling differences, etc., and no missing values.\n",
    "```\n",
    "df['category'].unique()\n",
    "```\n",
    "The categories are indeed unique.\n",
    "To be able to use the outputs publicly, I need to encode the categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df['category_enc'] = labelencoder.fit_transform(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = len(df['category_enc'].unique())\n",
    "no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by category\n",
    "cat_counts = df.groupby(['category_enc'])['rss_title'].count().sort_values()\n",
    "ax = cat_counts.plot.bar(logy=True, title='Number of data points in each category')\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell outputs above we can see that the dataset contains 24 categories and is heavily imbalanced - one of the categories has only 6 datapoints while the other contains ~46K(~41% of the whole dataset)).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I would like to see if there are any outliers (some of them have been already visible in the `df.head()`) in the `rss_perex` column.\n",
    "```\n",
    "df[df['rss_perex'].str.len() < 20]\n",
    "```\n",
    "There indeed are 3500 of them. These anomalies were brought to life by mistakes during web scraping: publication date of the article, a subtitle, an author, etc. However, even the subtitles can be useful for classification in our case (e.g. 'Bundesliga' is closely associated with soccer). \n",
    "\n",
    "It was also beneficial to know that neither `rss_perex` nor `rss_title` have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['rss_perex'].str.len() < 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['rss_title'] + ' ' + df['rss_perex']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is rather large, it is also imbalanced.\n",
    "Before I try any simpler methods, I use a text processing method that became highly popular in the last couple of years - transformers. Instead of training one from scratch I can use a pretrained one and utilize a latent space of its embedding to vectorize the sentences and then build a shallow network for classification.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge is finding a suitable model for embedding the sentences - most of the widely used models are trained for the English language.\n",
    "However, I was able to find multiple multi-language transformers (e.g. [Roberta](https://tfhub.dev/jeongukjae/xlm_roberta_multi_cased_L-24_H-1024_A-16/1)) and a [model trained on the Czech Wikipedia dump](https://tfhub.dev/google/wiki40b-lm-cs/1), which I decided to use. In retrospective, this was a very problematic model and I should have probably used a model [Small-E-Czech](https://huggingface.co/Seznam/small-e-czech). One of the problems, for example, was the fact that the model has an in-built tokenizer, thus the expected input is a raw sentence, however, the output is a 2d embedding of a variable length that had to be dealt with. Another concern is that, unfortunately, I have not find an available evaluation of the model, so using this model was indeed premature.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFHub model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = \"https://tfhub.dev/google/wiki40b-lm-cs/1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the embedding functionality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # Word embeddings.\n",
    "    text = tf.placeholder(dtype=tf.string, shape=(1,))\n",
    "    module = hub.Module(module_name)\n",
    "    embeddings = module(dict(text=text), signature=\"word_embeddings\",\n",
    "                        as_dict=True)\n",
    "    embeddings = embeddings[\"word_embeddings\"]\n",
    "    init_op = tf.group([tf.global_variables_initializer(),\n",
    "                      tf.tables_initializer()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session.\n",
    "with tf.Session(graph=g).as_default() as session:\n",
    "  session.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the embedding size of the largest perex. \n",
    "max_index = df['rss_perex'].str.len().argmax()\n",
    "longest_str = df[df.index == 9752]['rss_perex'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session.as_default():\n",
    "    em = session.run(embeddings, feed_dict={text: [longest_str]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = np.shape(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], \n",
    "                                                    df['category_enc'], \n",
    "                                                    stratify=df['category_enc'], \n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    stratify=y_train, \n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25) # 0.25 x 0.8 = 0.2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"This layer is necessary to pad the sentences of variable size to the size of the largest embedding.\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def pad_up_to(self, t, max_in_dims, constant_values):\n",
    "        \"\"\"https://stackoverflow.com/a/48535322/13591234\"\"\"\n",
    "        s = tf.shape(t)\n",
    "        paddings = [[0, m-s[i]] for (i,m) in enumerate(max_in_dims)]\n",
    "        return tf.pad(t, paddings, 'CONSTANT', constant_values=constant_values)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = self.pad_up_to(inputs, max_in_dims=embed_dim, constant_values=0)\n",
    "        output = tf.reshape(output, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(hub.KerasLayer(module_name, \n",
    "                        input_shape=[], \n",
    "                        dtype=tf.string, \n",
    "                        trainable=False, \n",
    "                        signature=\"word_embeddings\",\n",
    "                        signature_outputs_as_dict=True \n",
    "                        ))\n",
    "model.add(PadLayer())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu', input_shape=(embed_dim[2],)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(no_classes, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In retrospect, this model has probably too many parameters and lower number of parameters would have sufficed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train.to_numpy(), \n",
    "          y_train.to_numpy(), \n",
    "          epochs=2, \n",
    "          batch_size=1,\n",
    "          validation_data=(X_val.to_numpy(),  y_val.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test.to_numpy(), y_test.to_numpy(), batch_size=1)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test data is 78%, it is not much considering how big is the dataset and the fact that 41% of the data is belongs to just one of the classes. However, the second epoch has shown some improvement in the training, thus it is probable that with higher number of epochs, the model can achieve higher precision. Unfortunately, the was needed to be short due to time and computational constraints.\n",
    "\n",
    "The next possible steps when training the model can be: \n",
    "- changing / tweaking the model's architecture; \n",
    "- using a different embedding model; \n",
    "- utilizing the `rss_title` better, e.g. using two heads for processing `rss_title` and `rss_perex` individually.\n",
    "\n",
    "Another thing that is left unfinished is verifying the balanced accuracy of the predictions.  \n",
    "\n",
    "Further (quite desperate) attempt to improve results can be translating text to English (e.g. using DeepL) and then applying classic verified methods for working with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources for further improvements of the embeddings \n",
    "[Czech word2vec model](https://zenodo.org/record/3975038#.Y9F4MrXMJPY), \n",
    "[Training word2vec](https://textminingonline.com/training-word2vec-model-on-english-wikipedia-by-gensim), \n",
    "[Scripts for custom training of word2vec](https://github.com/anastazie/nlp_czech_wiki)\n",
    "\n",
    "[Electra paper](https://arxiv.org/abs/2003.10555), \n",
    "[Small-e-Czech hf hub](https://huggingface.co/Seznam/small-e-czech), \n",
    "[Small-e-Czech github](https://github.com/seznam/small-e-czech),\n",
    "[Roberta transformer model](https://tfhub.dev/jeongukjae/xlm_roberta_multi_cased_L-24_H-1024_A-16/1)\n",
    "\n",
    "[Czech embeddings](https://dspace.cuni.cz/bitstream/handle/20.500.11956/147648/120397596.pdf?sequence=1),    \n",
    "[An evaluation of Czech word embeddings](https://aclanthology.org/W19-6107.pdf)\n",
    "\n",
    "#### Possible architectures can be tried from \n",
    "[Sparse categorical entropy classification](https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-sparse-categorical-crossentropy-in-keras.md), \n",
    "[Pretrained Embedding Keras](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html), \n",
    "[Classifying tweets example](https://towardsdatascience.com/text-classification-using-word-embeddings-and-deep-learning-in-python-classifying-tweets-from-6fe644fcfc81)\n",
    "\n",
    "\n",
    "### Czech Wikipedia transformer model\n",
    "[Embedding model](https://tfhub.dev/google/wiki40b-lm-cs/1),\n",
    "[Collab](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/wiki40b_lm.ipynb#scrollTo=sv2CmI7BdaML)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT-like model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "# https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-multilingual-cased\", num_labels=no_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_classification\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/a/65571687\n",
    "    \"\"\"\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Perex_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "\n",
    "        self.labels = df['category_enc'].tolist()\n",
    "        self.texts = tokenizer(df['text'].tolist(), \n",
    "                               padding='max_length', max_length = 512, \n",
    "                               truncation=True, return_tensors=\"pt\"\n",
    "                               )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.texts.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_stratified_into_train_val_test(df, stratify_colname='category_enc')\n",
    "train, val, test = Perex_Dataset(df_train, tokenizer), Perex_Dataset(df_val, tokenizer), Perex_Dataset(df_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(test)[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on validation data\n",
    "{'eval_loss': 0.08356519043445587, 'eval_f1': 0.981017282266466, 'eval_runtime': 217.2683, 'eval_samples_per_second': 76.785, 'eval_steps_per_second': 4.801, 'epoch': 2.0}\n",
    "\n",
    "#### Results on testing data\n",
    "{'test_loss': 0.07817238569259644, 'test_f1': 0.9824589477771943, 'test_runtime': 362.4899, 'test_samples_per_second': 76.706, 'test_steps_per_second': 4.795}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model gives us 98% of F1 score. This is a very good score since the f1 score takes into consideration recall as well as precision. This metric helps to account for the imbalance in the dataset. \n",
    "\n",
    "Direct comparison with the TF model is not possible, since a) the metric is different, b) during splitting the dataset into training and test partitions the training part was contaminated. But the conclusion can be given anyway, since the aforementioned problems give the TF an unfair advantage and the Distilbert model still achieves seemingly better performance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- [Sequence classification HF](https://huggingface.co/docs/transformers/tasks/sequence_classification)\n",
    "- [Text classification HF](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)\n",
    "- [Creating custom dataset](https://huggingface.co/transformers/v3.2.0/custom_datasets.html)\n",
    "\n",
    "#### Not utilized\n",
    "- [EncoderDecoderModel](https://huggingface.co/docs/transformers/model_doc/encoder-decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "399ba6da13f1a0ab27358d540618ecfafd37a842103cd8305f5c1fbe569841be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
