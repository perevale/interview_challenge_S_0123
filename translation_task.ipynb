{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cs.wikipedia.org/wiki/Logika\n",
    "dataset_file_path = './data/translation.csv'\n",
    "assert os.path.exists(dataset_file_path)\n",
    "df = pd.read_csv(dataset_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Czech</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Formální (matematická) logika je exaktní věda ...</td>\n",
       "      <td>Formal (mathematical) logic is an exact scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jazyk formální logiky je umělý formální, pro k...</td>\n",
       "      <td>The language of formal logic is an artificial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umělými formálními jazyky jsou jazyky všech ty...</td>\n",
       "      <td>Artificial formal languages are languages of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nelze tedy např. v jakékoli formální logice po...</td>\n",
       "      <td>Thus, for example, natural language cannot be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je to překročení hranic exaktního světa poruše...</td>\n",
       "      <td>It is crossing the boundaries of the exact wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logika v pojetí filosofie s podporou psycholog...</td>\n",
       "      <td>Logic as conceived by philosophy with the sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logika filosofická není exaktní věda, vypovídá...</td>\n",
       "      <td>Philosophical logic is not an exact science; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jejím centrálním motivem je lidské usuzování (...</td>\n",
       "      <td>Its central motif is human reasoning (not thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zkoumá podmínky vyplývání, tedy hledá požadavk...</td>\n",
       "      <td>It examines the conditions of entailment, i.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cílem logiky je určit množinu korektních argum...</td>\n",
       "      <td>The goal of logic is to determine the set of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Czech   \\\n",
       "0  Formální (matematická) logika je exaktní věda ...   \n",
       "1  Jazyk formální logiky je umělý formální, pro k...   \n",
       "2  Umělými formálními jazyky jsou jazyky všech ty...   \n",
       "3  Nelze tedy např. v jakékoli formální logice po...   \n",
       "4  Je to překročení hranic exaktního světa poruše...   \n",
       "5  Logika v pojetí filosofie s podporou psycholog...   \n",
       "6  Logika filosofická není exaktní věda, vypovídá...   \n",
       "7  Jejím centrálním motivem je lidské usuzování (...   \n",
       "8  Zkoumá podmínky vyplývání, tedy hledá požadavk...   \n",
       "9  Cílem logiky je určit množinu korektních argum...   \n",
       "\n",
       "                                             English  \n",
       "0   Formal (mathematical) logic is an exact scien...  \n",
       "1   The language of formal logic is an artificial...  \n",
       "2   Artificial formal languages are languages of ...  \n",
       "3   Thus, for example, natural language cannot be...  \n",
       "4   It is crossing the boundaries of the exact wo...  \n",
       "5   Logic as conceived by philosophy with the sup...  \n",
       "6   Philosophical logic is not an exact science; ...  \n",
       "7   Its central motif is human reasoning (not thi...  \n",
       "8   It examines the conditions of entailment, i.e...  \n",
       "9   The goal of logic is to determine the set of ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"sacrebleu\")\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-mul-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.src_lang = \"cs\"\n",
    "tokenizer.tgt_lang = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{'cs': str(row[1]), 'en': str(row[2])} for row in df.itertuples()]\n",
    "dataset = Dataset.from_dict({'translation': d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"cs\"\n",
    "target_lang = \"en\"\n",
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on training data\n",
    "{'eval_loss': 0.026741966605186462, 'eval_bleu': 100.0, 'eval_gen_len': 28.0, 'eval_runtime': 43.9061, 'eval_samples_per_second': 0.228, 'eval_steps_per_second': 0.114, 'epoch': 18.0}\n",
    "\n",
    "\n",
    "It is visible that after 18 epochs the model achieved 100% with SacreBLEU metric on the training dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      64171\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 64171,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 64171,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Formální (matematická) logika je exaktní věda používající umělý formální jazyk, který je schopný vypovídat jen a jen o entitách exaktního světa.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Formal (mathematical) logic is an exact science using an artificial formal language that is capable of telling only and only about entities of the exact world.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "- [Translation tutorial HF](https://huggingface.co/docs/transformers/tasks/translation)\n",
    "- [Translation tutorial #2 HF](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "399ba6da13f1a0ab27358d540618ecfafd37a842103cd8305f5c1fbe569841be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
